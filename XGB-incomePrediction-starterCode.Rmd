---
rlan---
title: "Income Prediction - Credit card offer or denail"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 2
    df_print: paged
---

/newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('/Users/sayemnasher/Downloads')
#change above to your working directory
```

```{r message=FALSE,  warning=FALSE}
library("tidyverse")
library("skimr")
library("readxl") # used to read excel files
library("dplyr") # used for data munging 
library("FNN") # used for knn regression (knn.reg function)
library("caret") # used for various predictive models
library("class") # for using confusion matrix function
library("rpart.plot") # used to plot decision tree
library("rpart")  # used for Regression tree
library("glmnet") # used for Lasso and Ridge regression
library('NeuralNetTools') # used to plot Neural Networks
library("PRROC") # top plot ROC curve
library("ROCR") # top plot lift curve
library("fastDummies")
library("tibble")
```

# 1. Classification

## 1.1 Data loading, exploration and preparation for modeling

There are customers with known income and those without known income (the training and test sets respectively). The data contain 48842 instances with a mix of continuous and discrete (train=32561, test=16281) in two files named "CL-income-train.csv" (this is the same as your homework file 'CL-income.xlsx') and "test.csv" respectively. Lets load the training data

```{r }
# Load the training data

#read the CSV file into a data frame 'income_df'
income_df_train <- read_csv("train-baggle.csv", col_types = "nffnfffffnff")

# lets look at all the variables
skim(income_df_train)

#do some exploratory analysis of the categorical features of the data

income_df_train %>%  keep(is.factor) %>%  summary()

# There are few features with more than 6 levels.
# We use the table() function to get the distribution for their values.
table(select(income_df_train, workClassification))
table(select(income_df_train, educationLevel))
table(select(income_df_train, occupation))
table(select(income_df_train, nativeCountry))

# There are missing values for workClassification, nativeCountry and occupation.
# The missing values are represented by an indicator variable of '?'.
# Let's replace these with 'UNK' instead.

income_df_train <- income_df_train %>%
  mutate(workClassification = recode(workClassification, "?" = "UNK")) %>%
  mutate(nativeCountry = recode(nativeCountry, "?" = "UNK")) %>%
  mutate(occupation = recode(occupation, "?" = "UNK")) 

# What do we now have?
table(select(income_df_train, workClassification))
table(select(income_df_train, occupation))
table(select(income_df_train, nativeCountry))


# Before we build our model, let's also recode our class levels to 0 and 1. 
income_df_train <- income_df_train %>%
  mutate(income = recode(income, "<=50K" = "0")) %>%
  mutate(income = recode(income, ">50K" = "1"))

# What do we now have?
summary(income_df_train[,"income"])

# create Y and X data frames
#we will need the y column as a vector (X to be a dataframe)
# dplyr allows us to do this by using 'pull' instead of select
income_df_train_y = income_df_train %>% pull("income") %>% as.factor()


income_df_train_x = income_df_train %>% select(-c("income"))

income_df_train_x_dummy <- dummy_cols(income_df_train_x, select_columns = c('workClassification', 'educationLevel', 'maritalStatus', 'occupation', 'relationship', 'race', 'gender', 'nativeCountry'), remove_selected_columns = TRUE)

```

```{r}
#import the file using #read the CSV file into a data frame 'income_df'
income_df_test <- read_csv("test-baggle.csv", col_types = "fnffnfffffnff")

#skim data
skim(income_df_test)

#exploratory analysis
income_df_test %>%  keep(is.factor) %>%  summary()

#Drop "?"
income_df_test <- income_df_test %>%
  mutate(workClassification = recode(workClassification, "?" = "UNK")) %>%
  mutate(nativeCountry = recode(nativeCountry, "?" = "UNK")) %>%
  mutate(occupation = recode(occupation, "?" = "UNK"))
#create a data frame called 'income_df_test_x' using the same steps as above

income_df_test_x <- income_df_test %>% select(-c("income"))

income_df_test_x_dummy <- dummy_cols(income_df_test_x, select_columns = c('workClassification', 'educationLevel', 'maritalStatus', 'occupation', 'relationship', 'race', 'gender', 'nativeCountry'), remove_selected_columns = TRUE)

income_df_test_x_dummy['nativeCountry_Holand-Netherlands'] <- 0

skim(income_df_test_x)

```

## 1.3 Split the data into trainig and validation

```{r }
# 75% of the data is used for training and rest for testing
smp_size <- floor(0.75 * nrow(income_df_train_x_dummy))

# randomly select row numbers for training data set
train_ind <- sample(seq_len(nrow(income_df_train_x_dummy)), size = smp_size)

# creating training and validation sets for x
income_x_train <- income_df_train_x_dummy[train_ind, ]
income_x_validation <- income_df_train_x_dummy[-train_ind, ]

# creating training and validation sets for y
income_y_train <- income_df_train_y[train_ind]
income_y_validation <- income_df_train_y[-train_ind]

# Create an empty data frame to store results from different models
clf_results <- data.frame(matrix(ncol = 5, nrow = 0))
names(clf_results) <- c("Model", "Accuracy", "Precision", "Recall", "F1")

# Create an empty data frame to store TP, TN, FP and FN values
cost_benefit_df <- data.frame(matrix(ncol = 5, nrow = 0))
names(cost_benefit_df) <- c("Model", "TP", "FN", "FP", "TN")

```

## 1.4 Fit a model (or multiple models) on the training data

```{r  message=FALSE,  warning=FALSE}
#choice of model(s) method is yours
#make sure that if you use kNN for instance that you normalize  the data
XG_clf_fit <- train(income_x_train,
                 income_y_train, 
                 method = "xgbTree",
                 preProc = c("center", "scale"))
```
```{r }
# print the final model
XG_clf_fit$finalModel
```
```{r }
# Predict on test data
XG_clf_predict <- predict(XG_clf_fit, income_df_test_x_dummy)
```

## 1.5 Evaluate on validation data

Look at the model performance on validation data. Various commands to look at the models' performance on the validation data. Note that you dont have the test data set's true values. Only I have them and I will give you the total profit after you upload your predictions

```{r }
## assumes you have a data frame y_validation_pred_num 
##which is the output prediction on validation set in factor form using your chosen threshold

## assumes you have data frames 'income_df_validation_y' and 'income_df_validation_y' 
## based on a 75% - 25% split of the training set into train and validation

##Print Confusion matrix, Accuracy, Sensitivity etc 
##first 2 arguments should be factors: prediction and actual
##confusionMatrix(prediction, actual, positive="1")

##make class '1' as the positive class


# a5 <-confusionMatrix(prediction, actual, positive="1")
# x1 <- confusionMatrix(prediction, actual, positive="1"))[["overall"]]
# y3 <- confusionMatrix(prediction, actual, positive="1")[["byClass"]]
# 
# 
# cat("Recall of positive class is", round (y3[["Recall"]],3), "/n")
# cat("Precision of positive class is", round (y3[["Precision"]],3), "/n")
# cat("F score of positive class is", round (y3[["F1"]],3), "/n")
# 
# #calculate AUC
# 
# 

# pred1 <- prediction(y_validation_pred_num, income_df_validation_y)
# rocs <- performance(pred1, "tpr", "fpr")
# 
# # calculate AUC for all models
# AUC_models <- performance(pred1, "auc")
# auc_logistic = round(AUC_models@y.values[[1]], 3)
# cat("AUC is", auc_logistic)
# 
# 
# #unpack the confusion matrix
# 
#   TP = a5[["table"]][4]
#   FP = a5[["table"]][2]
#   FN = a5[["table"]][3]
#   TN = a5[["table"]][1]
  
#calculate profit

```

## 1.6 if you have landed on a model you can predict on the test data and save your solution

```{r }
# shows you sample code if your best model was yyy_fit. 
# Predict on test data
yyy_predict <- predict(yyy_fit, newdata = income_df_test_x)
#predict probabilties
yyy_predict_prob <- predict(yyy_fit, newdata = income_df_test_x, type="prob")

```

## 1.7 Convert probability outcome into categorical outcome based on a choice of threshold

```{r }
#here is an example with a 0.5 threshold. this is also the default in R
#you can set any threshold between 0 and 1
#you may find that profit/performance is different for different thresholds

y_pred_num <- ifelse(yyy_predict_prob[,2] > 0.5, 1, 0)
y_pred_factor <- as.factor(ifelse(yyy_predict_prob[,2] > 0.5, "1", "0"))
```

# 2. get ready to submit scored solution for contest

```{r}

#these are all the teams -- copy and paste your team and ignore the others
#"BannerAI", "CEOPredictions","FinancialDatawESG", "ImprovingHealthcare",
#"MapChange", "MediaAssetFairValueEstimator", "SmarketingB2BFunnel",
#"Vertex", "WalmartChannelOptimization"

filename <- "<pickone from above corresponding to your team"

scoreAllOne <- y_pred_factor  #assuming your prediction in factor form is in y_pred_factor
Id <- seq(1,nrow(income_df_test),1) #this is just the index number

tempScoreFrame <- data.frame(Id, scoreAllOne) #create a new data frame with 2 columns
names(tempScoreFrame) <- c("Id", "income") #give names to the 2 columns


write.csv(tempScoreFrame, paste(trim(filename), ".csv"), row.names=FALSE)

#check this file in Excel to see it looks ok
#upload this to Classes under competition assignment for day 1 and day 2


```
