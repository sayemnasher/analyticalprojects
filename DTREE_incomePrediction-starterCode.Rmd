---
title: "Income Prediction - Credit card offer or denail"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 2
    df_print: paged
---
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('/Users/sayemnasher/Downloads')
```


```{r message=FALSE,  warning=FALSE}
sm <- suppressMessages
sm (library("tidyverse"))
sm (library("skimr"))
sm (library("readxl")) # used to read excel files
sm (library("dplyr")) # used for data munging 
sm (library("FNN")) # used for knn regression (knn.reg function)
sm (library("caret")) # used for various predictive models
sm (library("class")) # for using confusion matrix function
sm (library("rpart.plot")) # used to plot decision tree
sm (library("rpart"))  # used for Regression tree
sm (library("glmnet")) # used for Lasso and Ridge regression
sm (library('NeuralNetTools')) # used to plot Neural Networks
sm (library("PRROC")) # top plot ROC curve
sm (library("ROCR")) # top plot lift curve

```


# 1. Classification


## 1.1 Data loading,  exploration and preparation for modeling

There are customers with known income and those without known income (the training and test sets respectively). The data contain 48842 instances with a mix of continuous and discrete (train=32561, test=16281) in two files named “CL-income-train.csv” (this is the same as your homework file 'CL-income.xlsx') and “test.csv” respectively. Lets load the training data

```{r }
# Load the training data

#read the CSV file into a data frame 'income_df'
income_df_train <- read_csv("train-baggle.csv", col_types = "nffnfffffnff")

# lets look at all the variables
skim(income_df_train)

#do some exploratory analysis of the categorical features of the data

income_df_train %>%  keep(is.factor) %>%  summary()

# There are few features with more than 6 levels.
# We use the table() function to get the distribution for their values.
table(select(income_df_train, workClassification))
table(select(income_df_train, educationLevel))
table(select(income_df_train, occupation))
table(select(income_df_train, nativeCountry))

# There are missing values for workClassification, nativeCountry and occupation.
# The missing values are represented by an indicator variable of '?'.
# Let's replace these with 'UNK' instead.

income_df_train <- income_df_train %>%
  mutate(workClassification = recode(workClassification, "?" = "UNK")) %>%
  mutate(nativeCountry = recode(nativeCountry, "?" = "UNK")) %>%
  mutate(occupation = recode(occupation, "?" = "UNK")) 

# What do we now have?
table(select(income_df_train, workClassification))
table(select(income_df_train, occupation))
table(select(income_df_train, nativeCountry))


# Before we build our model, let's also recode our class levels to 0 and 1. 
income_df_train <- income_df_train %>%
  mutate(income = recode(income, "<=50K" = "0")) %>%
  mutate(income = recode(income, ">50K" = "1"))

# What do we now have?
summary(income_df_train[,"income"])

# create Y and X data frames
#we will need the y column as a vector (X to be a dataframe)
# dplyr allows us to do this by using 'pull' instead of select
income_df_train_y = income_df_train %>% pull("income") 


income_df_train_x = income_df_train %>% select(-c("income"))



```


## 1.2 Load the test data set and do the same pre-processing

```{r }

#import the file using #read the CSV file into a data frame 'income_df'
income_df_test <- read_csv("test-baggle.csv", col_types = "fnffnfffffnff")

#skim data
skim(income_df_test)

#exploratory analysis
income_df_test %>%  keep(is.factor) %>%  summary()

#Drop "?"
income_df_test <- income_df_test %>%
  mutate(workClassification = recode(workClassification, "?" = "UNK")) %>%
  mutate(nativeCountry = recode(nativeCountry, "?" = "UNK")) %>%
  mutate(occupation = recode(occupation, "?" = "UNK"))
#create a data frame called 'income_df_test_x' using the same steps as above

income_df_test_x <- income_df_test %>% select(-c("income"))

```

## 1.3 Split the data into training and validation
```{r }
# 75% of the data is used for training and rest for testing
smp_size <- floor(0.75 * nrow(income_df_train_x))

# randomly select row numbers for training data set
train_ind <- sample(seq_len(nrow(income_df_train_x)), size = smp_size)

# creating training and validation sets for x
income_x_train <- income_df_train_x[train_ind, ]
income_x_validation <- income_df_train_x[-train_ind, ]

# creating training and validation sets for y
income_y_train <- income_df_train_y[train_ind]
income_y_validation <- income_df_train_y[-train_ind]

# Create an empty data frame to store results from different models
clf_results <- data.frame(matrix(ncol = 5, nrow = 0))
names(clf_results) <- c("Model", "Accuracy", "Precision", "Recall", "F1")

# Create an empty data frame to store TP, TN, FP and FN values
cost_benefit_df <- data.frame(matrix(ncol = 5, nrow = 0))
names(cost_benefit_df) <- c("Model", "TP", "FN", "FP", "TN")

```


## 1.4 Fit a model (or multiple models) on the training data
```{r  message=FALSE,  warning=FALSE}
#choice of model(s) method is yours
#make sure that if you use kNN for instance that you normalize  the data
# Cross validation
cross_validation <- trainControl(## 10-fold CV
                                method = "repeatedcv",
                                number = 10,
                                ## repeated three times
                                repeats = 3)

Param_Grid <-  expand.grid(maxdepth = 2:10)

dtree_fit <- train(income_x_train,
                 income_y_train, 
                 method = "rpart2",
                 parms = list(split = "gini"),
                tuneGrid = Param_Grid,
                 trControl = cross_validation,
                 preProc = c("center", "scale"))

dtree_fit
```

#print model
```{r }
# print the final model
dtree_fit$finalModel
```

```{r }
# Plot decision tree
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)
```


## 1.5 Evaluate on validation data

```{r }
# Predict on validation data
dtree_predict <- predict(dtree_fit, newdata = income_x_validation)
```

```{r }
# Print Confusion matrix, Accuarcy, Sensitivity etc 
confusionMatrix(dtree_predict,  income_y_validation , positive = "1")

# Add results into clf_results dataframe
x2 <- confusionMatrix(dtree_predict,  income_y_validation , positive = "1")[["overall"]]
y2 <- confusionMatrix(dtree_predict,  income_y_validation , positive = "1")[["byClass"]]

clf_results[nrow(clf_results) + 1,] <-  list(Model = "Decision Tree", 
                                             Accuracy = round (x2[["Accuracy"]],3), 
                                            Precision = round (y2[["Precision"]],3), 
                                            Recall = round (y2[["Recall"]],3), 
                                            F1 = round (y2[["F1"]],3))

# Print Accuracy and F1 score

cat("Accuarcy is ", round(x2[["Accuracy"]],3), "and F1 is ", round (y2[["F1"]],3)  )

# Add results into cost_benefit_df dataframe for cost benefit analysis 
a2 <- confusionMatrix(dtree_predict,  income_y_validation)

cost_benefit_df[nrow(cost_benefit_df) + 1,] <-  list(Model = "Decision Tree", 
                                             TP = a2[["table"]][4], 
                                             FN = a2[["table"]][3], 
                                             FP = a2[["table"]][2], 
                                             TN = a2[["table"]][1])

```

#calculate profit
```{r}

benefit_TP = 1400
benefit_TN = 10
cost_FN = -800
cost_FP = -1200

cost_benefit_df <- cost_benefit_df %>% 
                    mutate(Profit = (benefit_TP * TP) + (benefit_TN * TN) + 
                                    (cost_FP * FP) + (cost_FN * FN))

print(cost_benefit_df)
```

Look at the model performance on validation data. Various commands to look at the models' performance on the validation data. Note that you dont have the test data set's true values. Only I have them and I will give you the total profit after you upload your predictions

```{r }
## assume you have a data frame y_validation_pred_num 
##which is the output prediction on validation set in factor form using your chosen threshold

## assumes you have data frames 'income_df_validation_y' and 'income_df_validation_y' 
## based on a 75% - 25% split of the training set into train and validation

##Print Confusion matrix, Accuracy, Sensitivity etc 
##first 2 arguments should be factors: prediction and actual
##confusionMatrix(prediction, actual, positive="1")

##make class '1' as the positive class


# a5 <-confusionMatrix(prediction, actual, positive="1")
# x1 <- confusionMatrix(prediction, actual, positive="1"))[["overall"]]
# y3 <- confusionMatrix(prediction, actual, positive="1")[["byClass"]]
# 
# 
# cat("Recall of positive class is", round (y3[["Recall"]],3), "\n")
# cat("Precision of positive class is", round (y3[["Precision"]],3), "\n")
# cat("F score of positive class is", round (y3[["F1"]],3), "\n")
# 
# #calculate AUC
# 
# 

# pred1 <- prediction(y_validation_pred_num, income_df_validation_y)
# rocs <- performance(pred1, "tpr", "fpr")
# 
# # calculate AUC for all models
# AUC_models <- performance(pred1, "auc")
# auc_logistic = round(AUC_models@y.values[[1]], 3)
# cat("AUC is", auc_logistic)
# 
# 
# #unpack the confusion matrix
# 
#   TP = a5[["table"]][4]
#   FP = a5[["table"]][2]
#   FN = a5[["table"]][3]
#   TN = a5[["table"]][1]
  
#calculate profit

```


## 1.6 if you have landed on a model you can predict on the test data and save your solution
```{r }
# shows you sample code if your best model was yyy_fit. 
# Predict on test data
yyy_predict <- predict(dtree_fit, newdata = income_df_test_x)
#predict probabilties
yyy_predict_prob <- predict(dtree_fit, newdata = income_df_test_x, type="prob")
```

## 1.7 Convert probability outcome into categorical outcome based on a choice of threshold

```{r }
#here is an example with a 0.5 threshold. this is also the default in R
#you can set any threshold between 0 and 1
#you may find that profit/performance is different for different thresholds

y_pred_num <- ifelse(yyy_predict_prob[,2] > 0.5, 1, 0)
y_pred_factor <- as.factor(ifelse(yyy_predict_prob[,2] > 0.5, "1", "0"))
```


# 2. get ready to submit scored solution for contest
```{r}

#these are all the teams -- copy and paste your team and ignore the others
#"BannerAI", "CEOPredictions","FinancialDatawESG", "ImprovingHealthcare",
#"MapChange", "MediaAssetFairValueEstimator", "SmarketingB2BFunnel",
#"Vertex", "WalmartChannelOptimization"

filename <- "<MediciAnalytics>"

scoreAllOne <- y_pred_factor  #assuming your prediction in factor form is in y_pred_factor
Id <- seq(1,nrow(income_df_test),1) #this is just the index number

tempScoreFrame <- data.frame(Id, scoreAllOne) #create a new data frame with 2 columns
names(tempScoreFrame) <- c("Id", "income") #give names to the 2 columns


write.csv(tempScoreFrame, paste(trimws(filename), ".csv"), row.names=FALSE)
#check this file in Excel to see it looks ok
#upload this to Classes under competition assignment for day 1 and day 2


```